@article{SciML_C_Rak,
  author    = {Christopher Rackauckas and
               Yingbo Ma and
               Julius Martensen and
               Collin Warner and
               Kirill Zubov and
               Rohit Supekar and
               Dominic Skinner and
               Ali Jasim Ramadhan},
  title     = {Universal Differential Equations for Scientific Machine Learning},
  journal   = {CoRR},
  volume    = {abs/2001.04385},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.04385},
  eprinttype = {arXiv},
  eprint    = {2001.04385},
  timestamp = {Fri, 17 Jan 2020 14:07:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2001-04385.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
} 

@inproceedings{garg2009evolution,
  title={Evolution of an online social aggregation network: an empirical study},
  author={Garg, Sanchit and Gupta, Trinabh and Carlsson, Niklas and Mahanti, Anirban},
  booktitle={Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement},
  pages={315--321},
  year={2009}
}

@inproceedings{zhao2012multi,
  title={Multi-scale dynamics in a massive online social network},
  author={Zhao, Xiaohan and Sala, Alessandra and Wilson, Christo and Wang, Xiao and Gaito, Sabrina and Zheng, Haitao and Zhao, Ben Y},
  booktitle={Proceedings of the 2012 Internet Measurement Conference},
  pages={171--184},
  year={2012}
}
@article {Runghen2021,
	author = {Runghen, Rogini and Stouffer, Daniel B and Dalla Riva, Giulio V},
	title = {Exploiting node metadata to predict interactions in large networks using graph embedding and neural networks},
	elocation-id = {2021.06.10.447991},
	year = {2021},
	doi = {10.1101/2021.06.10.447991},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2021/06/11/2021.06.10.447991},
	eprint = {https://www.biorxiv.org/content/early/2021/06/11/2021.06.10.447991.full.pdf},
	journal = {bioRxiv}
}
@incollection{golub1971singular,
  title={Singular value decomposition and least squares solutions},
  author={Golub, Gene H and Reinsch, Christian},
  booktitle={Linear algebra},
  pages={134--151},
  year={1971},
  publisher={Springer}
}
@article{karniadakis2021physics,
  title={Physics-informed machine learning},
  author={Karniadakis, George Em and Kevrekidis, Ioannis G and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  journal={Nature Reviews Physics},
  volume={3},
  number={6},
  pages={422--440},
  year={2021},
  publisher={Nature Publishing Group}
}
@inproceedings{NEURIPS2020_c9f2f917,
 author = {Cranmer, Miles and Sanchez Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {17429--17442},
 publisher = {Curran Associates, Inc.},
 title = {Discovering Symbolic Models from Deep Learning with Inductive Biases},
 url = {https://proceedings.neurips.cc/paper/2020/file/c9f2f917078bd2db12f23c3b413d9cba-Paper.pdf},
 volume = {33},
 year = {2020}
}
@article{GAO2021110079,
title = {PhyGeoNet: Physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain},
journal = {Journal of Computational Physics},
volume = {428},
pages = {110079},
year = {2021},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2020.110079},
url = {https://www.sciencedirect.com/science/article/pii/S0021999120308536},
author = {Han Gao and Luning Sun and Jian-Xun Wang},
keywords = {Physics-informed neural networks, Label-free, Surrogate modeling, Physics-constrained deep learning, Partial differential equations, Navier-Stokes},
abstract = {Recently, the advent of deep learning has spurred interest in the development of physics-informed neural networks (PINN) for efficiently solving partial differential equations (PDEs), particularly in a parametric setting. Among all different classes of deep neural networks, the convolutional neural network (CNN) has attracted increasing attention in the scientific machine learning community, since the parameter-sharing feature in CNN enables efficient learning for problems with large-scale spatiotemporal fields. However, one of the biggest challenges is that CNN only can handle regular geometries with image-like format (i.e., rectangular domains with uniform grids). In this paper, we propose a novel physics-constrained CNN learning architecture, aiming to learn solutions of parametric PDEs on irregular domains without any labeled data. In order to leverage powerful classic CNN backbones, elliptic coordinate mapping is introduced to enable coordinate transforms between the irregular physical domain and regular reference domain. The proposed method has been assessed by solving a number of steady-state PDEs on irregular domains, including heat equations, Navier-Stokes equations, and Poisson equations with parameterized boundary conditions, varying geometries, and spatially-varying source fields. Moreover, the proposed method has also been compared against the state-of-the-art PINN with fully-connected neural network (FC-NN) formulation. The numerical results demonstrate the effectiveness of the proposed approach and exhibit notable superiority over the FC-NN based PINN in terms of efficiency and accuracy.}
}
@article{massaroli2020dissecting,
  title={Dissecting neural odes},
  author={Massaroli, Stefano and Poli, Michael and Park, Jinkyoo and Yamashita, Atsushi and Asama, Hajime},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3952--3963},
  year={2020}
}
@article {Dandekar2020.04.03.20052084,
	author = {Dandekar, Raj and Barbastathis, George},
	title = {Quantifying the effect of quarantine control in Covid-19 infectious spread using machine learning},
	elocation-id = {2020.04.03.20052084},
	year = {2020},
	doi = {10.1101/2020.04.03.20052084},
	publisher = {Cold Spring Harbor Laboratory Press},
	abstract = {Since the first recording of what we now call Covid-19 infection in Wuhan, Hubei province, China on Dec 31, 2019 (CHP 2020), the disease has spread worldwide and met with a wide variety of social distancing and quarantine policies. The effectiveness of these responses is notoriously difficult to quantify as individuals travel, violate policies deliberately or inadvertently, and infect others without themselves being detected (Li et al. 2020a; Wu \&amp; Leung 2020; Wang et al. 2020; Chinazzi et al. 2020; Ferguson et al. 2020; Kraemer et al. 2020). Moreover, the publicly available data on infection rates are themselves unreliable due to limited testing and even possibly under-reporting (Li et al. 2020b). In this paper, we attempt to interpret and extrapolate from publicly available data using a mixed first-principles epidemiological equations and data-driven neural network model. Leveraging our neural network augmented model, we focus our analysis on four locales: Wuhan, Italy, South Korea and the United States of America, and compare the role played by the quarantine and isolation measures in each of these countries in controlling the effective reproduction number Rt of the virus. Our results unequivocally indicate that the countries in which rapid government interventions and strict public health measures for quarantine and isolation were implemented were successful in halting the spread of infection and prevent it from exploding exponentially. In the case of Wuhan especially, where the available data were earliest available, we have been able to test the predicting ability of our model by training it from data in the January 24th till March 3rd window, and then matching the predictions up to April 1st. Even for Italy and South Korea, we have a buffer window of one week (25 March - 1 April) to validate the predictions of our model. In the case of the US, our model captures well the current infected curve growth and predicts a halting of infection spread by 20 April 2020. We further demonstrate that relaxing or reversing quarantine measures right now will lead to an exponential explosion in the infected case count, thus nullifying the role played by all measures implemented in the US since mid March 2020.Competing Interest StatementThe authors have declared no competing interest.Funding StatementThis effort was partially funded by the Intelligence Advanced Reseach Projects Activity (IARPA.)Author DeclarationsAll relevant ethical guidelines have been followed; any necessary IRB and/or ethics committee approvals have been obtained and details of the IRB/oversight body are included in the manuscript.YesAll necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.YesData for the infected and recovered case count in Wuhan is obtained from the data released by the Chinese National Health Commission. Infected and recovered count data for Italy, South Korea and USA is obtained from the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University.},
	URL = {https://www.medrxiv.org/content/early/2020/04/06/2020.04.03.20052084},
	eprint = {https://www.medrxiv.org/content/early/2020/04/06/2020.04.03.20052084.full.pdf},
	journal = {medRxiv}
}
@article{poli2019graph,
  title={Graph neural ordinary differential equations},
  author={Poli, Michael and Massaroli, Stefano and Park, Junyoung and Yamashita, Atsushi and Asama, Hajime and Park, Jinkyoo},
  journal={arXiv preprint arXiv:1911.07532},
  year={2019}
}
@article{krishnapriyan2021characterizing,
  title={Characterizing possible failure modes in physics-informed neural networks},
  author={Krishnapriyan, Aditi and Gholami, Amir and Zhe, Shandian and Kirby, Robert and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26548--26560},
  year={2021}
}
@article{roehrl2020modeling,
  title={Modeling system dynamics with physics-informed neural networks based on lagrangian mechanics},
  author={Roehrl, Manuel A and Runkler, Thomas A and Brandtstetter, Veronika and Tokic, Michel and Obermayer, Stefan},
  journal={IFAC-PapersOnLine},
  volume={53},
  number={2},
  pages={9195--9200},
  year={2020},
  publisher={Elsevier}
}
@article{mahmoudabadbozchelou2021data,
  title={Data-driven physics-informed constitutive metamodeling of complex fluids: A multifidelity neural network (MFNN) framework},
  author={Mahmoudabadbozchelou, Mohammadamin and Caggioni, Marco and Shahsavari, Setareh and Hartt, William H and Em Karniadakis, George and Jamali, Safa},
  journal={Journal of Rheology},
  volume={65},
  number={2},
  pages={179--198},
  year={2021},
  publisher={The Society of Rheology}
}
@article{nguyen2022physics,
  title={Physics-informed neural networks for non-Newtonian fluid thermo-mechanical problems: an application to rubber calendering process},
  author={Nguyen, Thi Nguyen Khoa and Dairay, Thibault and Meunier, Rapha{\"e}l and Mougeot, Mathilde},
  journal={arXiv preprint arXiv:2201.13389},
  year={2022}
}
@article{hoff2002latent,
  title={Latent space approaches to social network analysis},
  author={Hoff, Peter D and Raftery, Adrian E and Handcock, Mark S},
  journal={Journal of the american Statistical association},
  volume={97},
  number={460},
  pages={1090--1098},
  year={2002},
  publisher={Taylor \& Francis}
}

@article{schmidt2009distilling,
  title={Distilling free-form natural laws from experimental data},
  author={Schmidt, Michael and Lipson, Hod},
  journal={science},
  volume={324},
  number={5923},
  pages={81--85},
  year={2009},
  publisher={American Association for the Advancement of Science}
}

@article{bongard2007automated,
  title={Automated reverse engineering of nonlinear dynamical systems},
  author={Bongard, Josh and Lipson, Hod},
  journal={Proceedings of the National Academy of Sciences},
  volume={104},
  number={24},
  pages={9943--9948},
  year={2007},
  publisher={National Acad Sciences}
}

@article{kidger2022neural,
  title={On neural differential equations},
  author={Kidger, Patrick},
  journal={arXiv preprint arXiv:2202.02435},
  year={2022}
}

@article{moinet2015burstiness,
  title={Burstiness and aging in social temporal networks},
  author={Moinet, Antoine and Starnini, Michele and Pastor-Satorras, Romualdo},
  journal={Physical review letters},
  volume={114},
  number={10},
  pages={108701},
  year={2015},
  publisher={APS}
}

@article{hanneke2010discrete,
  title={Discrete temporal models of social networks},
  author={Hanneke, Steve and Fu, Wenjie and Xing, Eric P},
  year={2010}
}
